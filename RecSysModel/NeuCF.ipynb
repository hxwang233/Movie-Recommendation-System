{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Avail 11.0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Avail\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"./ml-1m/ratings.dat\",delimiter='::',dtype=int)[:,[0,1,3]]\n",
    "N_USERS = np.max(dataset[:,0])\n",
    "N_ITEMS = np.max(dataset[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items:  3952\n",
      "number of flows:  1000209\n",
      "avg of S(x):  253.0\n",
      "parameter phi:  0.00025\n",
      "parameter epsilon should less than or equal phi\n",
      "sketch belongs to half of the stream\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def veiwData(dataset):\n",
    "    n_users  = np.max(dataset[:,0])\n",
    "    n_items  = np.max(dataset[:,1])\n",
    "    avgS     = round(len(dataset) / n_items, 0)\n",
    "    itemFreq = [0 for x in range(n_items)]\n",
    "    for record in dataset:\n",
    "        itemFreq[record[1]-1] += 1\n",
    "    realHH = set()\n",
    "    for i,n in enumerate(itemFreq):\n",
    "        if n >= avgS:\n",
    "            realHH.add(i+1)\n",
    "    itemFreq.sort(reverse=True)\n",
    "    plt.plot(range(len(itemFreq)), itemFreq)\n",
    "    print(\"number of items: \", n_items)\n",
    "    print(\"number of flows: \", len(dataset))\n",
    "    print(\"avg of S(x): \", avgS)\n",
    "    print(\"parameter phi: \", round(1 / n_items, 5))\n",
    "    print(\"parameter epsilon should less than or equal phi\")\n",
    "    print(\"sketch belongs to half of the stream\")\n",
    "    return realHH\n",
    "\n",
    "realHH = veiwData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_table(\"./ml-1m/users.dat\", sep = '::', header = None, engine = 'python').iloc[:,0].values\n",
    "movies = pd.read_table(\"./ml-1m/movies.dat\", sep = '::', header = None, engine = 'python').iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "n_negatives = 4  ## 1正例对应n个负例 ##\n",
    "users_items = np.zeros((N_USERS+1, N_ITEMS+1), dtype = np.int8)  # 混淆矩阵\n",
    "user_input, item_input, labels = [],[],[]  # x1 x2 -> y\n",
    "for u in range(dataset.shape[0]):   # 评分数据集隐式化\n",
    "    users_items[dataset[u][0], dataset[u][1]] = 1\n",
    "uipositives = list() # 作为测试集的交互正例\n",
    "for i in range(N_USERS+1):\n",
    "    if i==0: \n",
    "        continue\n",
    "    uitems = dataset[dataset[:,0]==i]\n",
    "    onepos = uitems[uitems[:,-1]==np.max(uitems),:2][0]\n",
    "    uipositives.append(onepos)\n",
    "    users_items[onepos[0], onepos[1]]=0\n",
    "for uno, uitems in enumerate(users_items):\n",
    "    if uno == 0:\n",
    "        continue\n",
    "    positives = np.nonzero(uitems)[0]\n",
    "    n_sample = len(positives) * n_negatives\n",
    "    negative_items = list(set(range(N_ITEMS+1))^set(positives))\n",
    "    negatives = np.random.choice(negative_items, n_sample)  # 负采样 -- 不放回\n",
    "    for i in range(len(positives)): # 正实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(positives[i])\n",
    "        labels.append(1)\n",
    "    for j in range(n_sample): # 负实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(negatives[j])\n",
    "        labels.append(0)\n",
    "user_input = np.array(user_input)\n",
    "item_input = np.array(item_input)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "utest = list()\n",
    "itest = list()\n",
    "for ui in uipositives:\n",
    "    u = ui[0]\n",
    "    i = ui[1]\n",
    "    positives = np.nonzero(users_items[u])[0]\n",
    "    negative_items = list(set(range(1,N_ITEMS+1))^set(positives))\n",
    "    negatives_sample = np.random.choice(negative_items, 999)  # 负采样 -- 不放回\n",
    "    negatives = [i]  # 正例\n",
    "    for n in negatives_sample:\n",
    "        negatives.append(n)  # 添加负例\n",
    "    utest.append([u for j in range(1000)])\n",
    "    itest.append(negatives)\n",
    "ytest = np.zeros((N_USERS,1000))\n",
    "ytest[:, 0] = 1\n",
    "utest = np.array(utest)\n",
    "itest = np.array(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "USER_VECTOR_SIZE = 1        # len(one-hot of user vecter) \n",
    "ITEM_VECTOR_SIZE = 1        # len(one-hot of item vecter) \n",
    "LAYERS = [64, 32, 16, 8]    # MLP  0层为输入层  0层/2为嵌入层  \n",
    "GMF_N_FACTORS  = 8          # GMF隐层size  \n",
    "ACTIVATION = torch.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x1 = torch.from_numpy(user_input.reshape(-1, 1)).type(torch.LongTensor)\n",
    "torch_x2 = torch.from_numpy(item_input.reshape(-1, 1)).type(torch.LongTensor)\n",
    "torch_y  = torch.from_numpy(labels.reshape(-1, 1)).type(torch.FloatTensor)\n",
    "\n",
    "torch_dataset = data_utils.TensorDataset(torch_x1, torch_x2, torch_y)\n",
    "loader = data_utils.DataLoader(dataset = torch_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_vector_size, item_vector_size, gmf_n_factors, layers,  \n",
    "                 n_users, n_items, activation = torch.relu, batch_normalization = False, n_output = 1):\n",
    "        super(NCF, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.do_bn = batch_normalization\n",
    "        self.fcs = []\n",
    "        self.bns = []\n",
    "        self.n_layer  = len(layers)\n",
    "        parameter_LeCun = np.sqrt(gmf_n_factors + layers[-1])\n",
    "\n",
    "        #self.bn_userInput = nn.BatchNorm1d(1)   # for input data\n",
    "        #self.bn_itemInput = nn.BatchNorm1d(1)   # for input data\n",
    "        \n",
    "        self.mlp_user_embedding_layer = nn.Embedding(n_users+1, int(layers[0]/2))\n",
    "        self._set_normalInit(self.mlp_user_embedding_layer, hasBias = False) \n",
    "        self.mlp_item_embedding_layer = nn.Embedding(n_items+1, int(layers[0]/2))\n",
    "        self._set_normalInit(self.mlp_item_embedding_layer, hasBias = False) \n",
    "        \n",
    "        self.gmf_user_embedding_layer = nn.Embedding(n_users+1, gmf_n_factors)\n",
    "        self._set_normalInit(self.gmf_user_embedding_layer, hasBias = False) \n",
    "        self.gmf_item_embedding_layer = nn.Embedding(n_items+1, gmf_n_factors)\n",
    "        self._set_normalInit(self.gmf_item_embedding_layer, hasBias = False) \n",
    "        \n",
    "        for i in range(1, self.n_layer):               # build hidden layers and BN layers\n",
    "            fc = nn.Linear(layers[i-1], layers[i])\n",
    "            self._set_normalInit(fc)                  # parameters initialization\n",
    "            setattr(self, 'fc%i' % i, fc)       # IMPORTANT set layer to the Module\n",
    "            self.fcs.append(fc)\n",
    "            if self.do_bn:\n",
    "                bn = nn.BatchNorm1d(layers[i])\n",
    "                setattr(self, 'bn%i' % i, bn)   # IMPORTANT set layer to the Module\n",
    "                self.bns.append(bn)\n",
    "\n",
    "        self.predict = nn.Linear(gmf_n_factors + layers[-1], n_output)         # output layer\n",
    "        self._set_uniformInit(self.predict, parameter = parameter_LeCun)            # parameters initialization\n",
    "        return\n",
    "\n",
    "    def _set_normalInit(self, layer, parameter = [0.0, 0.01], hasBias=True):\n",
    "        init.normal_(layer.weight, mean = parameter[0], std = parameter[1])\n",
    "        if hasBias:\n",
    "            init.normal_(layer.bias, mean = parameter[0], std = parameter[1])\n",
    "        return\n",
    "    \n",
    "    def _set_uniformInit(self, layer, parameter = 5, hasBias = True):\n",
    "        init.uniform_(layer.weight, a = - parameter, b = parameter)\n",
    "        if hasBias:\n",
    "            init.uniform_(layer.bias, a = - parameter, b = parameter)\n",
    "        return\n",
    "    \n",
    "    def _set_heNormalInit(self, layer, hasBias=True):\n",
    "        init.kaiming_normal_(layer.weight, nonlinearity='relu')\n",
    "        if hasBias:\n",
    "            init.kaiming_normal_(layer.bias, nonlinearity='relu')\n",
    "        return\n",
    "    \n",
    "    def _set_heUniformInit(self, layer, hasBias=True):\n",
    "        init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "        if hasBias:\n",
    "            init.kaiming_uniform_(layer.bias, nonlinearity='relu')\n",
    "        return\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        #if self.do_bn: \n",
    "            #x1 = self.bn_userInput(x1)     # input batch normalization\n",
    "            #x2 = self.bn_itemInput(x2)\n",
    "        mlp_x1 = self.mlp_user_embedding_layer(x1)\n",
    "        mlp_x2 = self.mlp_item_embedding_layer(x2)\n",
    "        \n",
    "        gmf_x1 = self.gmf_user_embedding_layer(x1)\n",
    "        gmf_x2 = self.gmf_item_embedding_layer(x2)\n",
    "        \n",
    "        mlp_x3 = torch.cat((mlp_x1, mlp_x2), dim=1)\n",
    "        mlp_x  = torch.flatten(mlp_x3, start_dim=1)        \n",
    "        for i in range(1, self.n_layer):\n",
    "            mlp_x = self.fcs[i-1](mlp_x)\n",
    "            if self.do_bn: \n",
    "                mlp_x = self.bns[i-1](mlp_x)   # batch normalization\n",
    "            mlp_x = self.activation(mlp_x)\n",
    "        \n",
    "        gmf_x3 = torch.mul(gmf_x1, gmf_x2)\n",
    "        gmf_x  = torch.flatten(gmf_x3, start_dim=1)\n",
    "\n",
    "        x = torch.cat((mlp_x, gmf_x), dim=1)\n",
    "        out = torch.sigmoid(self.predict(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (mlp_user_embedding_layer): Embedding(6041, 32)\n",
      "  (mlp_item_embedding_layer): Embedding(3953, 32)\n",
      "  (gmf_user_embedding_layer): Embedding(6041, 8)\n",
      "  (gmf_item_embedding_layer): Embedding(3953, 8)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (predict): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ncf = NCF(user_vector_size = USER_VECTOR_SIZE, item_vector_size = ITEM_VECTOR_SIZE, gmf_n_factors = GMF_N_FACTORS, \n",
    "          layers = LAYERS, n_users = N_USERS, n_items = N_ITEMS, activation = ACTIVATION, batch_normalization = False, n_output = 1)\n",
    "optimizer = torch.optim.Adam(ncf.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = torch.nn.BCELoss()\n",
    "if(torch.cuda.is_available()):\n",
    "    ncf = ncf.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "print(ncf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    #HR击中率，如果topk中有正例ID即认为正确\n",
    "    if gtItem in ranklist:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    #NDCG归一化折损累计增益\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return np.log(2) / np.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def getH(ranklist1, ranklist2):\n",
    "    L = len(ranklist1)\n",
    "    common = len(list(set(ranklist1).intersection(set(ranklist2))))\n",
    "    return 1-common/L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movieEval_1(model, loss_func, utest, itest, ytest, topK = 100):\n",
    "    if len(utest)==len(itest)==len(ytest):\n",
    "        n_users = len(utest)\n",
    "    else:\n",
    "        print('the length of test sets are not equal.')\n",
    "        return\n",
    "    hit = 0\n",
    "    undcg = 0\n",
    "    rank_all_users = list()\n",
    "    test_loss = list()\n",
    "    for i in range(n_users):\n",
    "        map_item_score = dict()\n",
    "        x1test = Variable(torch.from_numpy(utest[i].reshape(-1, 1)).type(torch.LongTensor))\n",
    "        x2test = Variable(torch.from_numpy(itest[i].reshape(-1, 1)).type(torch.LongTensor))\n",
    "        y  = Variable(torch.from_numpy(ytest[i].reshape(-1, 1)).type(torch.FloatTensor))\n",
    "        x1test, x2test, y = x1test.cuda(), x2test.cuda(), y.cuda()\n",
    "        prediction = model(x1test, x2test)\n",
    "        loss = loss_func(prediction, y)\n",
    "        test_loss.append(loss.cpu().item())\n",
    "        pred_vector = prediction.cpu().data.numpy().T[0]\n",
    "        positive_item = itest[i][0]  # 取正例\n",
    "        for j in range(len(itest[i])):\n",
    "            map_item_score[itest[i][j]] = pred_vector[j]\n",
    "        ranklist = heapq.nlargest(topK, map_item_score, key=map_item_score.get)\n",
    "        rank_all_users.append(ranklist)\n",
    "        hit += getHitRatio(ranklist, positive_item)\n",
    "        undcg += getNDCG(ranklist, positive_item)\n",
    "    mean_test_loss = np.mean(test_loss)\n",
    "    hr = hit / n_users\n",
    "    ndcg = undcg / n_users\n",
    "    print('test_loss:', mean_test_loss)\n",
    "    print('HR@', topK, ' = %.4f' % hr)\n",
    "    print('NDCG@', topK, ' = %.4f' % ndcg)\n",
    "    return mean_test_loss, hr, ndcg, rank_all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movieEval_2(rank_all_users, movies, topK = 100):\n",
    "    n_users = len(rank_all_users)\n",
    "    n_movies = len(movies)\n",
    "    \n",
    "    # 评估个性化\n",
    "    h_list = list()\n",
    "    for i in range(n_users - 1):\n",
    "        for j in range(i + 1, n_users):\n",
    "            h_list.append(getH(rank_all_users[i], rank_all_users[j]))\n",
    "    personalization = np.mean(h_list)\n",
    "    \n",
    "    # 评估新颖性\n",
    "    I_all_user = list()\n",
    "    for ranklist in rank_all_users:\n",
    "        I_user = list()\n",
    "        for i in ranklist:\n",
    "            k = 0\n",
    "            for temp in rank_all_users:\n",
    "                if i in temp:\n",
    "                    k += 1\n",
    "            I_user.append(np.log2(n_users / k))\n",
    "        I_all_user.append(np.mean(I_user))\n",
    "    surprisal = np.mean(I_all_user)\n",
    "    \n",
    "    #评估覆盖率(熵度量)\n",
    "    entropy = 0\n",
    "    count = 0.0\n",
    "    p = dict()\n",
    "    for i in movies:\n",
    "        p[i] = 0\n",
    "        for ranklist in rank_all_users: \n",
    "            if i in ranklist:\n",
    "                p[i] += 1\n",
    "                count += 1\n",
    "    for v in p.values():\n",
    "        if v != 0:\n",
    "            temp = v/count\n",
    "            entropy -= temp * np.log2(temp) \n",
    "\n",
    "    #评估覆盖率\n",
    "    r = set()\n",
    "    for ranklist in rank_all_users:\n",
    "        for i in ranklist:\n",
    "            r.add(i)\n",
    "    coverage = len(r) / len(movies)\n",
    "    \n",
    "    print('Personalization@', topK, ' = %.4f' % personalization)\n",
    "    print('Surprisal@', topK, ' = %.4f' % surprisal)\n",
    "    print('Entropy@', topK, ' = %.4f' % entropy)\n",
    "    print('Coverage@', topK, ' = %.4f' % coverage)\n",
    "    return personalization, surprisal, entropy, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1个epoch------\n",
      "train_loss: 0.3109931338205128\n",
      "test_loss: 0.14944629559651115\n",
      "HR@ 100  = 0.6525\n",
      "NDCG@ 100  = 0.1831\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = list()\n",
    "test_loss_list  = list()\n",
    "hr_list = list()\n",
    "ndcg_list = list()\n",
    "p_list = list()\n",
    "s_list = list()\n",
    "e_list = list()\n",
    "c_list = list()\n",
    "for e in range(EPOCH):\n",
    "    train_loss = list()\n",
    "    for step, (batch_x1, batch_x2, batch_y) in enumerate(loader):\n",
    "        x1, x2, y = Variable(batch_x1), Variable(batch_x2), Variable(batch_y)\n",
    "        if (torch.cuda.is_available()):\n",
    "            x1, x2, y = x1.cuda(), x2.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = ncf(x1, x2)\n",
    "        loss = loss_func(prediction, y) \n",
    "        loss.backward()        \n",
    "        train_loss.append(loss.cpu().item())\n",
    "        optimizer.step()\n",
    "    print('------第'+str(e+1)+'个epoch------')\n",
    "    mean_train_loss = np.mean(train_loss)\n",
    "    print('train_loss:', mean_train_loss)\n",
    "    train_loss_list.append(mean_train_loss)    \n",
    "    test_loss, hr, ndcg, rank_all_users = movieEval_1(ncf, loss_func, utest, itest, ytest)\n",
    "    #personalization, surprisal, entropy, coverage = movieEval_2(rank_all_users, movies)\n",
    "    test_loss_list.append(test_loss)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)\n",
    "    #p_list.append(personalization)\n",
    "    #s_list.append(surprisal)\n",
    "    #e_list.append(entropy)\n",
    "    #c_list.append(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ncf,\"./model/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = torch.load(\"./model/model.pkl\")\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initSketch(sketch_deep, sketch_width):\n",
    "    sketch = [[(0,0,0) for x in range(sketch_width)] for y in range(sketch_deep)]\n",
    "    return sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.00025\n",
    "S = len(dataset)\n",
    "delta   = 0.05\n",
    "epsilon = 0.002\n",
    "r = round(np.log2(1 / delta)).astype(np.int)\n",
    "w = round(2 / epsilon)\n",
    "print(\"r =\", r)\n",
    "print(\"w =\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = initSketch(r, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(sketch, item):\n",
    "    sketch_deep  = len(sketch)\n",
    "    sketch_width = len(sketch[0])\n",
    "    x  = item[0]\n",
    "    vx = item[1]\n",
    "    for i in range(sketch_deep):\n",
    "        np.random.seed(i + x)\n",
    "        j = np.random.choice(sketch_width)\n",
    "        V = sketch[i][j][0] + vx\n",
    "        K = sketch[i][j][1]\n",
    "        C = sketch[i][j][2]\n",
    "        if K == x:\n",
    "            C += vx\n",
    "        else:\n",
    "            C -= vx\n",
    "            if C < 0:\n",
    "                K = x\n",
    "                C = -C\n",
    "        sketch[i][j] = (V, K, C)\n",
    "    return sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processStream_HH(sketch, dataset):\n",
    "    for record in dataset:\n",
    "        item = (record[1], 1)\n",
    "        update(sketch,item)\n",
    "    return \n",
    "\n",
    "data = dataset[dataset[:,2].argsort()]\n",
    "processStream_HH(sketch, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryU(sketch, x):\n",
    "    sketch_deep  = len(sketch)\n",
    "    sketch_width = len(sketch[0])\n",
    "    res_list = list()\n",
    "    for i in range(sketch_deep):\n",
    "        np.random.seed(i + x)\n",
    "        j = np.random.choice(sketch_width)\n",
    "        V = sketch[i][j][0]\n",
    "        K = sketch[i][j][1]\n",
    "        C = sketch[i][j][2] \n",
    "        if K == x:\n",
    "            S = (V + C) / 2\n",
    "        else:\n",
    "            S = (V - C) / 2\n",
    "        res_list.append(S)\n",
    "    return min(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryL(sketch, x):\n",
    "    sketch_deep  = len(sketch)\n",
    "    sketch_width = len(sketch[0])\n",
    "    res_list = list()\n",
    "    for i in range(sketch_deep):\n",
    "        np.random.seed(i + x)\n",
    "        j = np.random.choice(sketch_width)\n",
    "        K = sketch[i][j][1]\n",
    "        C = sketch[i][j][2] \n",
    "        if K == x:\n",
    "            S = C\n",
    "        else:\n",
    "            S = 0\n",
    "        res_list.append(S)\n",
    "    return max(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitter(sketch, phi, S):\n",
    "    print(\"heavy hitter threshold: \", phi * S)\n",
    "    hh = set()\n",
    "    sketch_deep  = len(sketch)\n",
    "    sketch_width = len(sketch[0])\n",
    "    for i in range(sketch_deep):\n",
    "        for j in range(sketch_width):\n",
    "            if sketch[i][j][0] >= phi * S:\n",
    "                x = sketch[i][j][1]\n",
    "                if queryU(sketch, x) >= phi * S:\n",
    "                    hh.add(x)\n",
    "    return hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resHH = hitter(sketch, phi, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(res, real):\n",
    "    tp = fp = fn = 0\n",
    "    for i in res:\n",
    "        if i in real:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for j in real:\n",
    "        if j not in res:\n",
    "            fn += 1\n",
    "    print(\"TP =\",tp,\"   FP =\", fp,\"   FN =\", fn)\n",
    "    recall = tp / (tp + fn)\n",
    "    print('reacall:', recall)\n",
    "    precision = tp / (tp + fp)\n",
    "    print('precision:',precision)\n",
    "    f1 = (2 * recall * precision) / (precision + recall)\n",
    "    print('F1-score:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(resHH, realHH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resHH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
