{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, user_vector_size, item_vector_size, mlp_embedding_size, mlp_n_layers, mlp_predict_size, n_output = 1):\n",
    "        ''' user_vector_size - user输入向量长度   item_vector_size - item输入向量长度\n",
    "            mlp_n_factors  -  MLP模型嵌入层神经元数目\n",
    "            mlp_n_layers - MLP模型层数   mlp_predict_size - MLP预测层神经元数目\n",
    "            n_output - 输出层神经元数目\n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        self.mlp_n_layers = mlp_n_layers\n",
    "        #mlp_firstLayer_size = int(mlp_predict_size * np.power(2, mlp_n_layers-1))\n",
    "        hidden_size = [mlp_predict_size]\n",
    "        for i in range(1, mlp_n_layers):\n",
    "            hidden_size.append(hidden_size[-1]*2)\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp_user_embedding_layer = nn.Linear(user_vector_size, mlp_embedding_size)\n",
    "        self.mlp_item_embedding_layer = nn.Linear(item_vector_size, mlp_embedding_size)\n",
    "        self.hidden = list()\n",
    "        for i in range(mlp_n_layers):\n",
    "            if i==0:\n",
    "                self.hidden.append(nn.Linear(2 * mlp_embedding_size, hidden_size[-1]))\n",
    "            else:\n",
    "                self.hidden.append(nn.Linear(hidden_size[mlp_n_layers-i], hidden_size[mlp_n_layers-i-1]))\n",
    "    \n",
    "        # NeuMF Layer\n",
    "        self.output_layer = nn.Linear(mlp_predict_size, n_output)\n",
    "        return\n",
    "    \n",
    "    def forward(self, user_input, item_input): # 多输入\n",
    "        # print('in forward', user_input.dtype)\n",
    "        # MLP\n",
    "        out01 = self.mlp_user_embedding_layer(user_input)\n",
    "        out02 = torch.relu(out01)\n",
    "        out11 = self.mlp_item_embedding_layer(item_input)\n",
    "        out12 = torch.relu(out11)\n",
    "        input_of_NCF = torch.cat((out02, out12), dim=1) # concatenation \n",
    "        #print('in forward', input_of_NCF.data.numpy().shape)\n",
    "        # MLP隐层全连接\n",
    "        out2x = list()\n",
    "        for i in range(1,self.mlp_n_layers+1):\n",
    "            if i==1:\n",
    "                out2x.append(self.hidden[i-1](input_of_NCF))\n",
    "                out2x.append(torch.relu(out2x[-1]))\n",
    "            else:\n",
    "                out2x.append(self.hidden[i-1](out2x[-1]))\n",
    "                out2x.append(torch.relu(out2x[-1]))\n",
    "        \n",
    "        #NeuMF Layer\n",
    "        out = torch.sigmoid(self.output_layer(out2x[-1]))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"./ml-1m/ratings.dat\",delimiter='::',dtype=int)[:,[0,1,3]]\n",
    "n_users = np.max(dataset[:,0])\n",
    "n_items = np.max(dataset[:,1])\n",
    "n_negatives = 4  ## 1正例对应n个负例 ##\n",
    "users_items = np.zeros((n_users+1, n_items+1), dtype = np.int8)  # 混淆矩阵\n",
    "user_input, item_input, labels = [],[],[]  # x1 x2 -> y\n",
    "for u in range(dataset.shape[0]):   # 评分数据集隐式化\n",
    "    users_items[dataset[u][0], dataset[u][1]] = 1\n",
    "uipositives = list() # 作为测试集的交互正例\n",
    "for i in range(n_users+1):\n",
    "    if i==0: \n",
    "        continue\n",
    "    uitems = dataset[dataset[:,0]==i]\n",
    "    onepos = uitems[uitems[:,-1]==np.max(uitems),:2][0]\n",
    "    uipositives.append(onepos)\n",
    "    users_items[onepos[0], onepos[1]]=0\n",
    "for uno, uitems in enumerate(users_items):\n",
    "    if uno == 0:\n",
    "        continue\n",
    "    positives = np.nonzero(uitems)[0]\n",
    "    n_sample = len(positives) * n_negatives\n",
    "    negative_items = list(set(range(n_items+1))^set(positives))\n",
    "    negatives = np.random.choice(negative_items, n_sample)  # 负采样 -- 不放回\n",
    "    for i in range(len(positives)): # 正实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(positives[i])\n",
    "        labels.append(1)\n",
    "    for j in range(n_sample): # 负实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(negatives[j])\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utest = list()\n",
    "itest = list()\n",
    "for ui in uipositives:\n",
    "    u = ui[0]\n",
    "    i = ui[1]\n",
    "    positives = np.nonzero(users_items[u])[0]\n",
    "    negative_items = list(set(range(1,n_items+1))^set(positives))\n",
    "    negatives = list(np.random.choice(negative_items, 100))  # 负采样 -- 不放回\n",
    "    negatives.append(i)\n",
    "    utest.append([u for j in range(101)])\n",
    "    itest.append(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCH = 20\n",
    "user_vector_size = 1    # len(one-hot of user vecter) \n",
    "item_vector_size = 1    # len(one-hot of item vecter) \n",
    "mlp_embedding_size = 8       # MLP 嵌入层神经元数\n",
    "mlp_n_layers  = 3       # MLP 隐层数\n",
    "mlp_predict_size = 16  # MLP 第一层神经元数  后续依次减半"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x1 = torch.from_numpy(np.array(user_input, ndmin=2).T).type(torch.FloatTensor)\n",
    "torch_x2 = torch.from_numpy(np.array(item_input, ndmin=2).T).type(torch.FloatTensor)\n",
    "torch_y  = torch.from_numpy(np.array(labels, ndmin=2).T).type(torch.FloatTensor)\n",
    "\n",
    "#x1 = Variable(torch.from_numpy(np.array(user_input, ndmin=2, dtype=np.flfloat).T))\n",
    "#x2 = Variable(torch.from_numpy(np.array(item_input, ndmin=2, dtype=np.float32).T))\n",
    "#y = Variable(torch.from_numpy(np.array(labels, ndmin=2, dtype=np.float32).T))\n",
    "torch_dataset = data_utils.TensorDataset(torch_x1,torch_x2,torch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data_utils.DataLoader(\n",
    "    dataset = torch_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data, mean=0, std=0.01)\n",
    "        nn.init.normal_(m.bias.data, mean=0, std=0.01)\n",
    "    return\n",
    "\n",
    "net = Net(user_vector_size = user_vector_size, item_vector_size = item_vector_size,\n",
    "          mlp_embedding_size = mlp_embedding_size, mlp_n_layers = mlp_n_layers, mlp_predict_size = mlp_predict_size, n_output = 1)\n",
    "net.apply(weights_init)\n",
    "print(net)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(EPOCH):\n",
    "    for step, (batch_x1, batch_x2, batch_y) in enumerate(loader):\n",
    "        x1, x2, y = Variable(batch_x1), Variable(batch_x2), Variable(batch_y)\n",
    "        prediction = net(x1, x2)\n",
    "        loss = loss_func(prediction, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Loss = %.4f' % loss.data)\n",
    "        \n",
    "        hit = 0\n",
    "        for i in range(n_users):\n",
    "            x1test = Variable(torch.from_numpy(np.array(utest[i], ndmin=2, dtype=np.float32).T))\n",
    "            x2test = Variable(torch.from_numpy(np.array(itest[i], ndmin=2, dtype=np.float32).T))\n",
    "            prediction = net(x1test, x2test)\n",
    "            #print(prediction.data)\n",
    "            itestResIndex = np.argsort(prediction.detach().numpy().T[0])\n",
    "            itestTopKIndex = itestResIndex[len(itestResIndex)-10:]\n",
    "            #print(itestTopKIndex)\n",
    "            if 100 in itestTopKIndex:\n",
    "                hit += 1\n",
    "        print('HR@10 = %.4f' % (hit/n_users))\n",
    "        break\n",
    "    break\n",
    "    #if e % 2 == 0:\n",
    "    print('------第'+str(e)+'个epoch------')\n",
    "    print('epoch loss = %.4f' % loss.data)\n",
    "    hit = 0\n",
    "    for i in range(n_users):\n",
    "        x1test = Variable(torch.from_numpy(np.array(utest[i], ndmin=2, dtype=np.float32).T))\n",
    "        x2test = Variable(torch.from_numpy(np.array(itest[i], ndmin=2, dtype=np.float32).T))\n",
    "        prediction = net(x1test, x2test)\n",
    "        print(prediction.data)\n",
    "        itestResIndex = np.argsort(prediction.detach().numpy().T[0])\n",
    "        itestTopKIndex = itestResIndex[len(itestResIndex)-10:]\n",
    "        print(itestTopKIndex)\n",
    "        if 100 in itestTopKIndex:\n",
    "            hit += 1\n",
    "    print('HR@10 = %.4f' % (hit/n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
