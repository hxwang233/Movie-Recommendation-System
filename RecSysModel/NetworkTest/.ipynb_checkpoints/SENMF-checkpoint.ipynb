{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('../ml-1m/ratings.dat', delimiter='::', usecols=[0,1,3], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items:  3952\n",
      "number of flows:  1000209\n",
      "avg of S(x):  253.0\n",
      "parameter phi:  0.00025\n",
      "parameter epsilon should less than or equal phi\n",
      "sketch belongs to half of the stream\n",
      "phi = 0.00025\n",
      "S = 1000209\n",
      "r = 4\n",
      "w = 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def veiwData(dataset):\n",
    "    n_users  = np.max(dataset[:,0])\n",
    "    n_items  = np.max(dataset[:,1])\n",
    "    avgS     = round(len(dataset) / n_items, 0)\n",
    "    itemFreq = [0 for x in range(n_items)]\n",
    "    for record in dataset:\n",
    "        itemFreq[record[1]-1] += 1\n",
    "    realHH = set()\n",
    "    for i,n in enumerate(itemFreq):\n",
    "        if n >= avgS:\n",
    "            realHH.add(i+1)\n",
    "    itemFreq.sort(reverse=True)\n",
    "    plt.plot(range(len(itemFreq)), itemFreq)\n",
    "    print(\"number of items: \", n_items)\n",
    "    print(\"number of flows: \", len(dataset))\n",
    "    print(\"avg of S(x): \", avgS)\n",
    "    print(\"parameter phi: \", round(1 / n_items, 5))\n",
    "    print(\"parameter epsilon should less than or equal phi\")\n",
    "    print(\"sketch belongs to half of the stream\")\n",
    "    return realHH, round(1 / n_items, 5), dataset.shape[0]\n",
    "\n",
    "realHH, phi, S = veiwData(dataset)\n",
    "print(\"phi =\", phi)\n",
    "print(\"S =\", S)\n",
    "delta   = 0.05\n",
    "epsilon = 0.002\n",
    "r = round(np.log2(1 / delta)).astype(np.int)\n",
    "w = round(2 / epsilon)\n",
    "print(\"r =\", r)\n",
    "print(\"w =\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HHtracer():\n",
    "    def __init__(self, sketch_width, sketch_deep):\n",
    "        self.sketch_width = sketch_width\n",
    "        self.sketch_deep  = sketch_deep \n",
    "        self.sketch = [[(0,0,0) for x in range(sketch_width)] for y in range(sketch_deep)]\n",
    "        return\n",
    "    \n",
    "    def processStream_HH(self, dataset):\n",
    "        for record in dataset:\n",
    "            item = (record[1], 1)\n",
    "            self.update(item)\n",
    "        return\n",
    "    \n",
    "    def update(self, item):\n",
    "        x  = item[0]\n",
    "        vx = item[1]\n",
    "        for i in range(self.sketch_deep):\n",
    "            np.random.seed(i + x)\n",
    "            j = np.random.choice(self.sketch_width)\n",
    "            V = self.sketch[i][j][0] + vx\n",
    "            K = self.sketch[i][j][1]\n",
    "            C = self.sketch[i][j][2]\n",
    "            if K == x:\n",
    "                C += vx\n",
    "            else:\n",
    "                C -= vx\n",
    "                if C < 0:\n",
    "                    K = x\n",
    "                    C = -C\n",
    "            self.sketch[i][j] = (V, K, C)\n",
    "        return\n",
    "    \n",
    "    def queryU(self, x):\n",
    "        res_list = list()\n",
    "        for i in range(self.sketch_deep):\n",
    "            np.random.seed(i + x)\n",
    "            j = np.random.choice(self.sketch_width)\n",
    "            V = self.sketch[i][j][0]\n",
    "            K = self.sketch[i][j][1]\n",
    "            C = self.sketch[i][j][2] \n",
    "            if K == x:\n",
    "                S = (V + C) / 2\n",
    "            else:\n",
    "                S = (V - C) / 2\n",
    "            res_list.append(S)\n",
    "        return min(res_list)   \n",
    "    \n",
    "    def hitter(self, phi, S):\n",
    "        print(\"heavy hitter threshold: \", phi * S)\n",
    "        hh = set()\n",
    "        for i in range(self.sketch_deep):\n",
    "            for j in range(self.sketch_width):\n",
    "                if self.sketch[i][j][0] >= phi * S:\n",
    "                    x = self.sketch[i][j][1]\n",
    "                    if self.queryU(x) >= phi * S:\n",
    "                        hh.add(x)\n",
    "        return hh\n",
    "    \n",
    "    def getHH(self, dataset, phi, S):\n",
    "        self.processStream_HH(dataset)\n",
    "        hh = self.hitter(phi, S)\n",
    "        return hh\n",
    "    \n",
    "    def evaluate(self, res, real):\n",
    "        tp = fp = fn = 0\n",
    "        for i in res:\n",
    "            if i in real:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        for j in real:\n",
    "            if j not in res:\n",
    "                fn += 1\n",
    "        print(\"TP =\",tp,\"   FP =\", fp,\"   FN =\", fn)\n",
    "        recall = tp / (tp + fn)\n",
    "        print('reacall:', recall)\n",
    "        precision = tp / (tp + fp)\n",
    "        print('precision:',precision)\n",
    "        f1 = (2 * recall * precision) / (precision + recall)\n",
    "        print('F1-score:',f1)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heavy hitter threshold:  250.05225000000002\n",
      "TP = 1115    FP = 45    FN = 91\n",
      "reacall: 0.9245439469320066\n",
      "precision: 0.9612068965517241\n",
      "F1-score: 0.9425190194420964\n"
     ]
    }
   ],
   "source": [
    "data = dataset[dataset[:,2].argsort()]  # (user,item,tiemstamp, ...)\n",
    "hh_tracer = HHtracer(w, r)\n",
    "resHH = hh_tracer.getHH(data, phi, S)\n",
    "hh_tracer.evaluate(resHH, realHH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train(dataset, n_user, n_item):\n",
    "    users_items = np.zeros((n_user+1, n_item+1), dtype = np.int8)\n",
    "    for line in dataset:\n",
    "        users_items[line[0],line[1]] = 1    \n",
    "    user_pos = dict()\n",
    "    max_item_id = users_items.shape[1]\n",
    "    max_item_num = 0\n",
    "    for u, i in enumerate(users_items):\n",
    "        if u == 0:\n",
    "            continue\n",
    "        pos_item = list(np.nonzero(i)[0])\n",
    "        pos_item_num = len(pos_item)\n",
    "        if  pos_item_num > max_item_num:\n",
    "            max_item_num = pos_item_num\n",
    "        user_pos[u] = pos_item\n",
    "    train_user = list()\n",
    "    train_item = list()\n",
    "    for k in user_pos.keys():\n",
    "        while len(user_pos[k]) < max_item_num:\n",
    "            user_pos[k].append(max_item_id)\n",
    "        train_user.append(k)\n",
    "        train_item.append(user_pos[k])\n",
    "    return np.array(train_user), np.array(train_item)\n",
    "\n",
    "def generate_test(dataset):\n",
    "    n_user = np.max(dataset[:,0])\n",
    "    n_item = np.max(dataset[:,1])\n",
    "    u_pos_test = list() # 作为测试集的交互正例\n",
    "    for i in range(n_user+1):\n",
    "        if i==0: \n",
    "            continue\n",
    "        uitems = dataset[dataset[:,0]==i]\n",
    "        onepos = list(uitems[uitems[:,-1]==np.max(uitems),:2][0])   # 每个用户取时间戳最大的交互\n",
    "        u_pos_test.append(onepos)\n",
    "    return np.array(u_pos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, hh):\n",
    "    n_user = np.max(dataset[:,0])\n",
    "    n_item = np.max(dataset[:,1])\n",
    "    test = generate_test(dataset)\n",
    "    freq_data = list()\n",
    "    tail_data = list()\n",
    "    for line in dataset:\n",
    "        if test[line[0]-1, 1] == line[1]:  # 若在测试集中->跳过\n",
    "            continue\n",
    "        if line[1] in hh:\n",
    "            freq_data.append(list(line))\n",
    "        else:\n",
    "            tail_data.append(list(line))\n",
    "    freq_data = np.array(freq_data)\n",
    "    tail_data = np.array(tail_data)\n",
    "    freq_u_train, freq_i_train = generate_train(freq_data,n_user,n_item)\n",
    "    tail_u_train, tail_i_train = generate_train(tail_data,n_user,n_item)\n",
    "    return freq_u_train, freq_i_train, tail_u_train, tail_i_train, test[:,0], test[:,1]\n",
    "train_user_freq, train_item_freq, train_user_tail, train_item_tail, test_user, test_item = split_data(dataset, resHH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USER = np.max(dataset[:,0])\n",
    "N_ITEM = np.max(dataset[:,1])\n",
    "EMB_SIZE = 64\n",
    "NEG_WEIGHT = 0.5\n",
    "DROP_RATIO = 0.5\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 512\n",
    "EPOCH = 200\n",
    "#RATIO = len(resHH)/N_ITEM\n",
    "RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_torch_x1 = torch.from_numpy(train_user_freq).type(torch.LongTensor)\n",
    "freq_torch_x2 = torch.from_numpy(train_item_freq).type(torch.LongTensor)\n",
    "tail_torch_x1 = torch.from_numpy(train_user_tail).type(torch.LongTensor)\n",
    "tail_torch_x2 = torch.from_numpy(train_item_tail).type(torch.LongTensor)\n",
    "\n",
    "freq_torch_dataset = data_utils.TensorDataset(freq_torch_x1, freq_torch_x2)\n",
    "tail_torch_dataset = data_utils.TensorDataset(tail_torch_x1, tail_torch_x2)\n",
    "freq_loader = data_utils.DataLoader(dataset = freq_torch_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)\n",
    "tail_loader = data_utils.DataLoader(dataset = tail_torch_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENMF(nn.Module):\n",
    "    def __init__(self, emb_size, n_user, n_item, neg_weight, drop_out):\n",
    "        super().__init__()\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.neg_weight = neg_weight\n",
    "        self.emb_size   = emb_size\n",
    "        self.user_embs = nn.Embedding(n_user+1, emb_size)\n",
    "        self.item_embs = nn.Embedding(n_item+2, emb_size)\n",
    "        self.h = nn.Parameter(torch.randn(emb_size, 1))\n",
    "        self.dropout = nn.Dropout(p=drop_out)\n",
    "        self._reset_para()\n",
    "        return\n",
    "    \n",
    "    def _reset_para(self):\n",
    "        nn.init.xavier_normal_(self.user_embs.weight)\n",
    "        nn.init.xavier_normal_(self.item_embs.weight)\n",
    "        nn.init.constant_(self.h, 0.01)\n",
    "        return\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        '''\n",
    "        u_emb = self.dropout(self.user_embs(users))\n",
    "        i_emb = self.item_embs(items)\n",
    "        mask = (~(items.eq(self.n_item+1))).float()\n",
    "        i_emb = i_emb * mask.unsqueeze(2)\n",
    "        temp = list()\n",
    "        for u,v in enumerate(u_emb):\n",
    "            temp.append(torch.mul(v,i_emb[u]))\n",
    "        pq = torch.stack(temp)\n",
    "        hpq = torch.bmm(pq, torch.repeat_interleave(self.h.unsqueeze(0), repeats=pq.shape[0], dim=0)).squeeze(2)\n",
    "        loss_pos = torch.sum((1 - self.neg_weight) * hpq.square() - 2.0 * hpq)\n",
    "        part1 = torch.mm(self.h, self.h.T)\n",
    "        part2 = torch.sum(torch.mm(u_emb.T,u_emb),0)\n",
    "        part3 = torch.sum(torch.mm(self.item_embs.weight.T,self.item_embs.weight),0)\n",
    "        #part3 = torch.sum(torch.bmm(i_emb.reshape(i_emb.shape[0],i_emb.shape[2],i_emb.shape[1]), i_emb),0)\n",
    "        #print(part1.shape)\n",
    "        #print(part2.shape)\n",
    "        #print(part3.shape)\n",
    "        loss_all_data = torch.sum(part1 * part2 * part3)\n",
    "        loss = loss_pos + self.neg_weight * loss_all_data\n",
    "        '''\n",
    "        u_emb = self.dropout(self.user_embs(users))\n",
    "        pos_embs = self.item_embs(items)\n",
    "        # torch.einsum(\"ab,abc->abc\")\n",
    "        # B * L * D\n",
    "        mask = (~(items.eq(self.n_item+1))).float()\n",
    "        pos_embs = pos_embs * mask.unsqueeze(2)\n",
    "        \n",
    "        # torch.einsum(\"ac,abc->abc\")\n",
    "        # B * L * D\n",
    "        pq = u_emb.unsqueeze(1) * pos_embs\n",
    "        # torch.einsum(\"ajk,kl->ajl\")\n",
    "        # B * L\n",
    "        hpq = pq.matmul(self.h).squeeze(2)\n",
    "        # loss\n",
    "        pos_data_loss = torch.sum((1 - self.neg_weight) * hpq.square() - 2.0 * hpq)\n",
    "        # torch.einsum(\"ab,ac->abc\")\n",
    "        part_1 = self.item_embs.weight.unsqueeze(2).bmm(self.item_embs.weight.unsqueeze(1))\n",
    "        part_2 = u_emb.unsqueeze(2).bmm(u_emb.unsqueeze(1))\n",
    "        # D * D\n",
    "        part_1 = part_1.sum(0)\n",
    "        part_2 = part_2.sum(0)\n",
    "        part_3 = self.h.mm(self.h.t())\n",
    "        all_data_loss = torch.sum(part_1 * part_2 * part_3)\n",
    "        loss = self.neg_weight * all_data_loss + pos_data_loss\n",
    "        return loss\n",
    "    \n",
    "    def rank(self, users):\n",
    "        uid_embs = self.user_embs(users).unsqueeze(1)\n",
    "        user_all_items = uid_embs * self.item_embs.weight\n",
    "        items_score = user_all_items.matmul(self.h).squeeze(2)  # 除0及占位符  返回id-1\n",
    "        return items_score[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    #HR击中率，如果topk中有正例ID即认为正确\n",
    "    if gtItem in ranklist:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    #NDCG归一化折损累计增益\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return np.log(2) / np.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def getH(ranklist1, ranklist2):\n",
    "    L = len(ranklist1)\n",
    "    common = len(list(set(ranklist1).intersection(set(ranklist2))))\n",
    "    return 1-common/L\n",
    "\n",
    "def movieEval_1(models, test_user, test_item, ratio = 0.5, topK = 100):\n",
    "    if len(test_user)==len(test_item):\n",
    "        n_users = len(test_user)\n",
    "    else:\n",
    "        print('the length of test sets are not equal.')\n",
    "        return\n",
    "    K = [int(ratio*topK), topK-int(ratio*topK)]\n",
    "    hit = 0\n",
    "    undcg = 0\n",
    "    rank_all_users = [[],[]]\n",
    "    for i, model in enumerate(models):\n",
    "        model = model.cpu()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(test_user).type(torch.LongTensor)\n",
    "            prediction = model.rank(x)\n",
    "            prediction = prediction.cpu().data.numpy()\n",
    "            for u, v in enumerate(prediction):\n",
    "                ranklist = heapq.nlargest(K[i], range(len(v)), v.take)\n",
    "                rank_all_users[i].append(ranklist)\n",
    "        model.train()\n",
    "        if (torch.cuda.is_available()):\n",
    "            model = model.cuda()\n",
    "    from_freq_model = rank_all_users[0]\n",
    "    from_tail_model = rank_all_users[1]\n",
    "    for u, items in enumerate(from_freq_model):\n",
    "        items.extend(from_tail_model[u])\n",
    "        hit += getHitRatio(items, gtItem=test_item[u]-1)\n",
    "        undcg += getNDCG(items, gtItem=test_item[u]-1)\n",
    "    hr = hit / n_users\n",
    "    ndcg = undcg / n_users\n",
    "    print('HR@', topK, ' = %.4f' % hr)\n",
    "    print('NDCG@', topK, ' = %.4f' % ndcg)\n",
    "    return hr, ndcg, rank_all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_model ENMF(\n",
      "  (user_embs): Embedding(6041, 64)\n",
      "  (item_embs): Embedding(3954, 64)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "tail_model ENMF(\n",
      "  (user_embs): Embedding(6041, 64)\n",
      "  (item_embs): Embedding(3954, 64)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "freq_model = ENMF(emb_size=EMB_SIZE, n_user=N_USER, n_item=N_ITEM, neg_weight=NEG_WEIGHT, drop_out = DROP_RATIO)\n",
    "tail_model = ENMF(emb_size=EMB_SIZE, n_user=N_USER, n_item=N_ITEM, neg_weight=NEG_WEIGHT, drop_out = DROP_RATIO)\n",
    "freq_optimizer = torch.optim.Adam(freq_model.parameters(), lr = LEARNING_RATE)\n",
    "tail_optimizer = torch.optim.Adam(tail_model.parameters(), lr = LEARNING_RATE)\n",
    "if(torch.cuda.is_available()):\n",
    "    freq_model = freq_model.cuda()\n",
    "    tail_model = tail_model.cuda()\n",
    "print('freq_model', freq_model)\n",
    "print('tail_model', tail_model)\n",
    "models = [freq_model, tail_model]\n",
    "optims = [freq_optimizer, tail_optimizer]\n",
    "loaders = [freq_loader, tail_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------第1个epoch------\n",
      "train_loss: 0.07700866061107565\n",
      "HR@ 100  = 0.0387\n",
      "NDCG@ 100  = 0.0096\n",
      "------第2个epoch------\n",
      "train_loss: -26.551939477523167\n",
      "HR@ 100  = 0.0720\n",
      "NDCG@ 100  = 0.0177\n",
      "------第3个epoch------\n",
      "train_loss: -467.6944483121236\n",
      "HR@ 100  = 0.0998\n",
      "NDCG@ 100  = 0.0241\n",
      "------第4个epoch------\n",
      "train_loss: -2683.3884785970054\n",
      "HR@ 100  = 0.1131\n",
      "NDCG@ 100  = 0.0271\n",
      "------第5个epoch------\n",
      "train_loss: -7152.594375610352\n",
      "HR@ 100  = 0.1219\n",
      "NDCG@ 100  = 0.0293\n",
      "------第6个epoch------\n",
      "train_loss: -11161.950764973959\n",
      "HR@ 100  = 0.1263\n",
      "NDCG@ 100  = 0.0294\n",
      "------第7个epoch------\n",
      "train_loss: -13850.70258585612\n",
      "HR@ 100  = 0.1250\n",
      "NDCG@ 100  = 0.0292\n",
      "------第8个epoch------\n",
      "train_loss: -14911.8918355306\n",
      "HR@ 100  = 0.1250\n",
      "NDCG@ 100  = 0.0297\n",
      "------第9个epoch------\n",
      "train_loss: -15480.157491048178\n",
      "HR@ 100  = 0.1361\n",
      "NDCG@ 100  = 0.0326\n",
      "------第10个epoch------\n",
      "train_loss: -15909.849416097006\n",
      "HR@ 100  = 0.1401\n",
      "NDCG@ 100  = 0.0338\n",
      "------第11个epoch------\n",
      "train_loss: -16193.700480143229\n",
      "HR@ 100  = 0.1454\n",
      "NDCG@ 100  = 0.0352\n",
      "------第12个epoch------\n",
      "train_loss: -16500.435546875\n",
      "HR@ 100  = 0.1487\n",
      "NDCG@ 100  = 0.0362\n",
      "------第13个epoch------\n",
      "train_loss: -16683.103037516277\n",
      "HR@ 100  = 0.1545\n",
      "NDCG@ 100  = 0.0371\n",
      "------第14个epoch------\n",
      "train_loss: -16927.789967854816\n",
      "HR@ 100  = 0.1540\n",
      "NDCG@ 100  = 0.0369\n",
      "------第15个epoch------\n",
      "train_loss: -17118.330576578777\n",
      "HR@ 100  = 0.1604\n",
      "NDCG@ 100  = 0.0380\n",
      "------第16个epoch------\n",
      "train_loss: -17303.25210571289\n",
      "HR@ 100  = 0.1634\n",
      "NDCG@ 100  = 0.0389\n",
      "------第17个epoch------\n",
      "train_loss: -17465.335408528645\n",
      "HR@ 100  = 0.1687\n",
      "NDCG@ 100  = 0.0401\n",
      "------第18个epoch------\n",
      "train_loss: -17601.842732747395\n",
      "HR@ 100  = 0.1719\n",
      "NDCG@ 100  = 0.0401\n",
      "------第19个epoch------\n",
      "train_loss: -17698.920928955078\n",
      "HR@ 100  = 0.1702\n",
      "NDCG@ 100  = 0.0403\n",
      "------第20个epoch------\n",
      "train_loss: -17860.85605875651\n",
      "HR@ 100  = 0.1705\n",
      "NDCG@ 100  = 0.0404\n",
      "------第21个epoch------\n",
      "train_loss: -17939.867126464844\n",
      "HR@ 100  = 0.1733\n",
      "NDCG@ 100  = 0.0409\n",
      "------第22个epoch------\n",
      "train_loss: -18030.215087890625\n",
      "HR@ 100  = 0.1765\n",
      "NDCG@ 100  = 0.0414\n",
      "------第23个epoch------\n",
      "train_loss: -18174.306213378906\n",
      "HR@ 100  = 0.1773\n",
      "NDCG@ 100  = 0.0410\n",
      "------第24个epoch------\n",
      "train_loss: -18254.024556477863\n",
      "HR@ 100  = 0.1828\n",
      "NDCG@ 100  = 0.0419\n",
      "------第25个epoch------\n",
      "train_loss: -18386.884440104168\n",
      "HR@ 100  = 0.1834\n",
      "NDCG@ 100  = 0.0422\n",
      "------第26个epoch------\n",
      "train_loss: -18458.394409179688\n",
      "HR@ 100  = 0.1841\n",
      "NDCG@ 100  = 0.0423\n",
      "------第27个epoch------\n",
      "train_loss: -18509.059611002605\n",
      "HR@ 100  = 0.1871\n",
      "NDCG@ 100  = 0.0426\n",
      "------第28个epoch------\n",
      "train_loss: -18606.625528971355\n",
      "HR@ 100  = 0.1879\n",
      "NDCG@ 100  = 0.0425\n",
      "------第29个epoch------\n",
      "train_loss: -18738.28065999349\n",
      "HR@ 100  = 0.1917\n",
      "NDCG@ 100  = 0.0434\n",
      "------第30个epoch------\n",
      "train_loss: -18832.01649983724\n",
      "HR@ 100  = 0.1904\n",
      "NDCG@ 100  = 0.0431\n",
      "------第31个epoch------\n",
      "train_loss: -18821.67832438151\n",
      "HR@ 100  = 0.1907\n",
      "NDCG@ 100  = 0.0434\n",
      "------第32个epoch------\n",
      "train_loss: -18949.90301513672\n",
      "HR@ 100  = 0.1911\n",
      "NDCG@ 100  = 0.0435\n",
      "------第33个epoch------\n",
      "train_loss: -18975.77490234375\n",
      "HR@ 100  = 0.1921\n",
      "NDCG@ 100  = 0.0438\n",
      "------第34个epoch------\n",
      "train_loss: -19034.275756835938\n",
      "HR@ 100  = 0.1929\n",
      "NDCG@ 100  = 0.0441\n",
      "------第35个epoch------\n",
      "train_loss: -19109.466247558594\n",
      "HR@ 100  = 0.1924\n",
      "NDCG@ 100  = 0.0437\n",
      "------第36个epoch------\n",
      "train_loss: -19107.060943603516\n",
      "HR@ 100  = 0.1947\n",
      "NDCG@ 100  = 0.0441\n",
      "------第37个epoch------\n",
      "train_loss: -19189.898864746094\n",
      "HR@ 100  = 0.1983\n",
      "NDCG@ 100  = 0.0448\n",
      "------第38个epoch------\n",
      "train_loss: -19253.568603515625\n",
      "HR@ 100  = 0.1990\n",
      "NDCG@ 100  = 0.0445\n",
      "------第39个epoch------\n",
      "train_loss: -19253.020914713543\n",
      "HR@ 100  = 0.1952\n",
      "NDCG@ 100  = 0.0437\n",
      "------第40个epoch------\n",
      "train_loss: -19319.785909016926\n",
      "HR@ 100  = 0.1990\n",
      "NDCG@ 100  = 0.0444\n",
      "------第41个epoch------\n",
      "train_loss: -19356.58009847005\n",
      "HR@ 100  = 0.1962\n",
      "NDCG@ 100  = 0.0440\n",
      "------第42个epoch------\n",
      "train_loss: -19402.692443847656\n",
      "HR@ 100  = 0.1960\n",
      "NDCG@ 100  = 0.0440\n",
      "------第43个epoch------\n",
      "train_loss: -19444.769755045574\n",
      "HR@ 100  = 0.1972\n",
      "NDCG@ 100  = 0.0440\n",
      "------第44个epoch------\n",
      "train_loss: -19513.19600423177\n",
      "HR@ 100  = 0.2015\n",
      "NDCG@ 100  = 0.0448\n",
      "------第45个epoch------\n",
      "train_loss: -19499.141174316406\n",
      "HR@ 100  = 0.2002\n",
      "NDCG@ 100  = 0.0449\n",
      "------第46个epoch------\n",
      "train_loss: -19572.26045735677\n",
      "HR@ 100  = 0.1977\n",
      "NDCG@ 100  = 0.0446\n",
      "------第47个epoch------\n",
      "train_loss: -19583.190775553387\n",
      "HR@ 100  = 0.2018\n",
      "NDCG@ 100  = 0.0449\n",
      "------第48个epoch------\n",
      "train_loss: -19590.74871826172\n",
      "HR@ 100  = 0.2002\n",
      "NDCG@ 100  = 0.0445\n",
      "------第49个epoch------\n",
      "train_loss: -19663.429545084637\n",
      "HR@ 100  = 0.1995\n",
      "NDCG@ 100  = 0.0444\n",
      "------第50个epoch------\n",
      "train_loss: -19633.89434814453\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = list()\n",
    "hr_list = list()\n",
    "ndcg_list = list()\n",
    "for model in models:\n",
    "    model.train() \n",
    "for e in range(EPOCH):\n",
    "    train_loss = list()\n",
    "    for i, model in enumerate(models):\n",
    "        for step, (batch_x1, batch_x2) in enumerate(loaders[i]):\n",
    "            x1, x2 = batch_x1, batch_x2\n",
    "            if (torch.cuda.is_available()):\n",
    "                x1, x2 = x1.cuda(), x2.cuda()\n",
    "            optims[i].zero_grad()\n",
    "            loss = model(x1, x2)\n",
    "            loss.backward()        \n",
    "            train_loss.append(loss.cpu().item())\n",
    "            optims[i].step()\n",
    "    print('------第'+str(e+1)+'个epoch------')\n",
    "    mean_train_loss = np.mean(train_loss)\n",
    "    print('train_loss:', mean_train_loss)\n",
    "    train_loss_list.append(mean_train_loss)    \n",
    "    hr, ndcg, rank_all_users = movieEval_1(models, test_user, test_item, ratio=RATIO)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
