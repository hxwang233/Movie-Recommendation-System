{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('../Yelp/yelp.rating', usecols=[0,1,3], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_SIZE = [64,32,16,8,4,2,1]\n",
    "N_FM = 32\n",
    "N_USERS = np.max(dataset[:,0])\n",
    "N_ITEMS = np.max(dataset[:,1])\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items = np.zeros((N_USERS+1,N_ITEMS+1), dtype=np.int8)\n",
    "for line in dataset:\n",
    "    users_items[line[0],line[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "user_input, item_input, labels = list(),list(),list()  # x1 x2 -> y\n",
    "n_negatives = 4  ## 1正例对应n个负例 ##\n",
    "uipositives = list() # 作为测试集的交互正例\n",
    "for i in range(N_USERS+1):\n",
    "    uitems = dataset[dataset[:,0]==i]\n",
    "    onepos = uitems[uitems[:,-1]==np.max(uitems),:2][0]\n",
    "    uipositives.append(onepos)\n",
    "    users_items[onepos[0], onepos[1]]=0\n",
    "for uno, uitems in enumerate(users_items):\n",
    "    positives = np.nonzero(uitems)[0]\n",
    "    n_sample = len(positives) * n_negatives\n",
    "    negative_items = list(set(range(N_ITEMS+1))^set(positives))\n",
    "    negatives = np.random.choice(negative_items, n_sample)  # 负采样 -- 不放回\n",
    "    for i in range(len(positives)): # 正实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(positives[i])\n",
    "        labels.append(1)\n",
    "    for j in range(n_sample): # 负实例\n",
    "        user_input.append(uno)\n",
    "        item_input.append(negatives[j])\n",
    "        labels.append(0)\n",
    "user_input = np.array(user_input)\n",
    "item_input = np.array(item_input)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "utest = list()\n",
    "itest = list()\n",
    "for ui in uipositives:\n",
    "    u = ui[0]\n",
    "    i = ui[1]\n",
    "    users_items[u, i] = 1\n",
    "    positives = np.nonzero(users_items[u])[0]\n",
    "    negative_items = list(set(range(N_ITEMS+1))^set(positives))\n",
    "    negatives_sample = np.random.choice(negative_items, 999)  # 负采样 -- 不放回\n",
    "    negatives = [i]  # 正例\n",
    "    for n in negatives_sample:\n",
    "        negatives.append(n)  # 添加负例\n",
    "    utest.append([u for j in range(1000)])\n",
    "    itest.append(negatives)\n",
    "ytest = np.zeros((N_USERS+1,1000))\n",
    "ytest[:, 0] = 1\n",
    "utest = np.array(utest)\n",
    "itest = np.array(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_x1 = torch.from_numpy(user_input.reshape(-1, 1)).type(torch.LongTensor)\n",
    "torch_x2 = torch.from_numpy(item_input.reshape(-1, 1)).type(torch.LongTensor)\n",
    "torch_y  = torch.from_numpy(labels.reshape(-1, 1)).type(torch.FloatTensor)\n",
    "\n",
    "torch_dataset = data_utils.TensorDataset(torch_x1, torch_x2, torch_y)\n",
    "loader = data_utils.DataLoader(dataset = torch_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNCF(nn.Module):\n",
    "    def __init__(self, fm_sizes, n_users, n_items, n_fm=N_FM, myStride=2, n_output=1):\n",
    "        ''' e.g.--> fm_sizes = [64,32,16,8,4,2,1] '''\n",
    "        super(ConvNCF, self).__init__()\n",
    "        self.convs = list()\n",
    "        \n",
    "        self.user_embedding_layer = nn.Embedding(n_users+1, fm_sizes[0])\n",
    "        self._set_normalInit(self.user_embedding_layer, hasBias = False) \n",
    "        self.item_embedding_layer = nn.Embedding(n_items+1, fm_sizes[0])\n",
    "        self._set_normalInit(self.item_embedding_layer, hasBias = False) \n",
    "        for i in range(1, len(fm_sizes)):\n",
    "            inChannel = 1 if i == 1 else n_fm\n",
    "            #conv = nn.Conv2d(in_channels=inChannel, out_channels=32, kernel_size=fm_sizes[i]+myStride, stride=myStride)\n",
    "            conv = nn.Conv2d(in_channels=inChannel, out_channels=n_fm, kernel_size=4, stride=myStride, padding=1)\n",
    "            #self._set_normalInit(conv)\n",
    "            setattr(self, 'conv%i' % i, conv)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.predict = nn.Linear(n_fm, n_output)         # output layer\n",
    "        #self._set_uniformInit(self.predict)            # parameters initialization\n",
    "        return\n",
    "    \n",
    "    def _set_normalInit(self, layer, parameter = [0.0, 0.01], hasBias = True):\n",
    "        init.normal_(layer.weight, mean = parameter[0], std = parameter[1])\n",
    "        if hasBias:\n",
    "            init.normal_(layer.bias, mean = parameter[0], std = parameter[1])\n",
    "        return\n",
    "    \n",
    "    def _set_uniformInit(self, layer, parameter = 1, hasBias = True):\n",
    "        init.uniform_(layer.weight, a = - parameter, b = parameter)\n",
    "        if hasBias:\n",
    "            init.uniform_(layer.bias, a = - parameter, b = parameter)\n",
    "        return\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        x1   = self.user_embedding_layer(user)\n",
    "        x2   = self.item_embedding_layer(item)\n",
    "        temp = list()\n",
    "        for i in range(x1.size()[0]):\n",
    "            temp.append(torch.mm(x1[i].T, x2[i]))\n",
    "        x = torch.stack(temp)\n",
    "        x = x.view(x.size()[0], -1, x.size()[1], x.size()[2])\n",
    "        ''' ## conv2d -input  (batch_size, channel, weight, height) '''\n",
    "        for conv in self.convs:\n",
    "            x = torch.relu(conv(x))\n",
    "        ''' ## conv2d -output (batch_size, out_channel, out_weight, out_height) '''\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        #print(x)\n",
    "        out = torch.sigmoid(self.predict(x))\n",
    "        #out = self.predict(x)\n",
    "        print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNCF(fm_sizes=FM_SIZE, n_fm=N_FM, n_users=N_USERS, n_items=N_ITEMS)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = torch.nn.BCELoss()\n",
    "if(torch.cuda.is_available()):\n",
    "    model = model.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    #HR击中率，如果topk中有正例ID即认为正确\n",
    "    if gtItem in ranklist:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    #NDCG归一化折损累计增益\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return np.log(2) / np.log(i+2)\n",
    "    return 0\n",
    "\n",
    "def getH(ranklist1, ranklist2):\n",
    "    L = len(ranklist1)\n",
    "    common = len(list(set(ranklist1).intersection(set(ranklist2))))\n",
    "    return 1-common/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movieEval_1(model, loss_func, utest, itest, ytest, topK = 10):\n",
    "    if len(utest)==len(itest)==len(ytest):\n",
    "        n_users = len(utest)\n",
    "    else:\n",
    "        print('the length of test sets are not equal.')\n",
    "        return\n",
    "    hit = 0\n",
    "    undcg = 0\n",
    "    rank_all_users = list()\n",
    "    test_loss = list()\n",
    "    for i in range(n_users):\n",
    "        map_item_score = dict()\n",
    "        x1test = Variable(torch.from_numpy(utest[i].reshape(-1, 1)).type(torch.LongTensor))\n",
    "        x2test = Variable(torch.from_numpy(itest[i].reshape(-1, 1)).type(torch.LongTensor))\n",
    "        y  = Variable(torch.from_numpy(ytest[i].reshape(-1, 1)).type(torch.FloatTensor))\n",
    "        x1test, x2test, y = x1test.cuda(), x2test.cuda(), y.cuda()\n",
    "        prediction = model(x1test, x2test)\n",
    "        #print(prediction)\n",
    "        loss = loss_func(prediction, y)\n",
    "        test_loss.append(loss.cpu().item())\n",
    "        pred_vector = prediction.cpu().data.numpy().T[0]\n",
    "        positive_item = itest[i][0]  # 取正例\n",
    "        for j in range(len(itest[i])):\n",
    "            map_item_score[itest[i][j]] = pred_vector[j]\n",
    "        ranklist = heapq.nlargest(topK, map_item_score, key=map_item_score.get)\n",
    "        rank_all_users.append(ranklist)\n",
    "        hit += getHitRatio(ranklist, positive_item)\n",
    "        undcg += getNDCG(ranklist, positive_item)\n",
    "    mean_test_loss = np.mean(test_loss)\n",
    "    hr = hit / n_users\n",
    "    ndcg = undcg / n_users\n",
    "    print('test_loss:', mean_test_loss)\n",
    "    print('HR@', topK, ' = %.4f' % hr)\n",
    "    print('NDCG@', topK, ' = %.4f' % ndcg)\n",
    "    return mean_test_loss, hr, ndcg, rank_all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = list()\n",
    "test_loss_list  = list()\n",
    "hr_list = list()\n",
    "ndcg_list = list()\n",
    "for e in range(EPOCH):\n",
    "    train_loss = list()\n",
    "    for step, (batch_x1, batch_x2, batch_y) in enumerate(loader):\n",
    "        x1, x2, y = Variable(batch_x1), Variable(batch_x2), Variable(batch_y)\n",
    "        if (torch.cuda.is_available()):\n",
    "            x1, x2, y = x1.cuda(), x2.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(x1, x2)\n",
    "        loss = loss_func(prediction, y) \n",
    "        loss.backward()        \n",
    "        train_loss.append(loss.cpu().item())\n",
    "        optimizer.step()\n",
    "    print('------第'+str(e+1)+'个epoch------')\n",
    "    mean_train_loss = np.mean(train_loss)\n",
    "    print('train_loss:', mean_train_loss)\n",
    "    train_loss_list.append(mean_train_loss)    \n",
    "    test_loss, hr, ndcg, rank_all_users = movieEval_1(model, loss_func, utest, itest, ytest)\n",
    "    test_loss_list.append(test_loss)\n",
    "    hr_list.append(hr)\n",
    "    ndcg_list.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
